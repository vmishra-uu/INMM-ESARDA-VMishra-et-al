{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MVA-PWR-INMM-ESARDA-VMISHRA-et-al.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihMjfqojFNXH"
      },
      "source": [
        "**Optimum hyperparameters for the three selected shallow learning algorithms**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrtXrVtUzea8"
      },
      "source": [
        "<table style=\"text-align:center; font-family: sans-serif; border-collapse:collapse;\">\n",
        "<caption style=\"text-align:left; padding: 10px;\"><strong>Table 1: Optimum hyperparameters for shallow learning algorithms</strong></caption>\n",
        "<tfoot><tr><td colspan=\"100%\" style=\"text-align:left;\">\n",
        "&diams; For k-NN regressor, the most important hyperparameters were the number of nearest neighbors and the distance metric.<br/>\n",
        "&dagger; For random forest regressor (RFR), the most important hyperparameter is the number of estimators.<br/>\n",
        "&Dagger; For AdaBoost regressor, the most important hyperparameters were the number of estimators and depth of the trees.<br/>\n",
        "&dagger;&dagger; information on the Canberra distance metric is available within <a href=\"https://arxiv.org/abs/1201.0490\">scikit-learn documentation</a>.<br/>\n",
        "</td></tr></tfoot>\n",
        "<thead style=\"border-top: 2px solid black; border-bottom: 2px solid black;\">\n",
        "  <tr>\n",
        "    <th rowspan=\"3\" style=\"padding: 10px;\">CT Regime</th>\n",
        "    <th rowspan=\"3\" style=\"padding: 10px;\">Output <br>Variable</th>\n",
        "    <th rowspan=\"3\" style=\"padding: 10px;\">Input Features</th>\n",
        "    <th colspan=\"4\" style=\"padding: 10px; border-bottom: 2px solid black;\">Hyperparameter Description</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td colspan=\"4\" style=\"text-align:center; padding: 10px; border-bottom: 2px solid black;\"><strong>Algorithm</strong></td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td colspan=\"2\" style=\"padding: 10px;\"><strong><em>k-</em>NN</strong> &diams;</td>\n",
        "    <td style=\"padding: 10px;\"><strong>RFR</strong> &dagger;</td>\n",
        "    <td style=\"padding: 10px;\"><strong>AdaBoost</strong> &Dagger;</td>\n",
        "  </tr>\n",
        "</thead>\n",
        "<tbody>\n",
        "  <tr>\n",
        "    <td rowspan=\"3\" style=\"padding: 10px\">CT &lt; 10 years</td>\n",
        "    <td style=\"padding-top: 10px\">BU</td>\n",
        "    <td rowspan=\"3\" style=\"padding-top: 10px\"><sup>141</sup>Ce, 95Nb, 95Zr, <sup>144</sup>Ce, <br><sup>106</sup>Ru, <sup>134</sup>Cs, <sup>154</sup>Eu, <sup>137</sup>Cs</td>\n",
        "    <td colspan=\"2\" style=\"padding-top: 10px\">5, Canberra &dagger;&dagger;</td>\n",
        "    <td style=\"padding-top: 10px\">300</td>\n",
        "    <td style=\"padding-top: 10px\">15, 15</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>IE</td>\n",
        "    <td colspan=\"2\">5, Canberra</td>\n",
        "    <td>300</td>\n",
        "    <td>25, 25</td>\n",
        "  </tr>\n",
        "  <tr style=\"border-bottom: 2px solid black;\">\n",
        "    <td style=\"padding-bottom: 10px\">CT</td>\n",
        "    <td colspan=\"2\" style=\"padding-bottom: 10px\">3, Canberra</td>\n",
        "    <td style=\"padding-bottom: 10px\">300</td>\n",
        "    <td style=\"padding-bottom: 10px\">25, 20</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td rowspan=\"3\" style=\"padding: 10px\">CT &lt; 20 years</td>\n",
        "    <td style=\"padding-top: 10px\">BU</td>\n",
        "    <td rowspan=\"3\"><sup>134</sup>Cs, <sup>154</sup>Eu, <sup>137</sup>Cs</td>\n",
        "    <td colspan=\"2\" style=\"padding-top: 10px\">5, Canberra</td>\n",
        "    <td style=\"padding-top: 10px\">400</td>\n",
        "    <td style=\"padding-top: 10px\">20, 17</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>IE</td>\n",
        "    <td colspan=\"2\">5, Canberra</td>\n",
        "    <td>300</td>\n",
        "    <td>25, 50</td>\n",
        "  </tr>\n",
        "  <tr style=\"border-bottom: 2px solid black;\">\n",
        "    <td style=\"padding-bottom: 10px\">CT</td>\n",
        "    <td colspan=\"2\" style=\"padding-bottom: 10px\">3, Canberra</td>\n",
        "    <td style=\"padding-bottom: 10px\">400</td>\n",
        "    <td style=\"padding-bottom: 10px\">20, 20</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td rowspan=\"6\" style=\"padding: 10px; border-bottom: 2px solid black;\">20 &le; CT &le; 70 years<br><br></td>\n",
        "    <td rowspan=\"2\" style=\"padding-top: 10px\">BU</td>\n",
        "    <td style=\"padding-top: 10px\"><sup>134</sup>Cs, <sup>154</sup>Eu, <sup>137</sup>Cs, Tot_A, tau</span></td>\n",
        "    <td colspan=\"2\" style=\"padding-top: 10px\">8, Canberra</td>\n",
        "    <td style=\"padding-top: 10px\">300</td>\n",
        "    <td style=\"padding-top: 10px\">15, 20</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td><sup>134</sup>Cs, <sup>154</sup>Eu, <sup>137</sup>Cs, Cherenkov, tau</span></td>\n",
        "    <td colspan=\"2\">8, Canberra</td>\n",
        "    <td>300</td>\n",
        "    <td>15, 20</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td rowspan=\"2\">IE</td>\n",
        "    <td><sup>134</sup>Cs, <sup>154</sup>Eu, <sup>137</sup>Cs, Tot_A, tau</span></td>\n",
        "    <td colspan=\"2\">6, Canberra</td>\n",
        "    <td>300</td>\n",
        "    <td>20, 50</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td><sup>134</sup>Cs, <sup>154</sup>Eu, <sup>137</sup>Cs, Cherenkov, tau</span></td>\n",
        "    <td colspan=\"2\">6, Canberra</td>\n",
        "    <td>300</td>\n",
        "    <td>20, 50</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td rowspan=\"2\" style=\"border-bottom: 2px solid black; padding-bottom: 10px;\">CT</td>\n",
        "    <td><sup>134</sup>Cs, <sup>154</sup>Eu, <sup>137</sup>Cs, Tot_A, tau</span></td>\n",
        "    <td colspan=\"2\">6, Canberra</td>\n",
        "    <td>400</td>\n",
        "    <td>30, 30</td>\n",
        "  </tr>\n",
        "  <tr style=\"border-bottom: 2px solid black;\">\n",
        "    <td style=\"padding-bottom: 10px\"><sup>134</sup>Cs, <sup>154</sup>Eu, <sup>137</sup>Cs, Cherenkov, tau</span></td>\n",
        "    <td colspan=\"2\" style=\"padding-bottom: 10px\">5, Canberra</td>\n",
        "    <td style=\"padding-bottom: 10px\">400</td>\n",
        "    <td style=\"padding-bottom: 10px\">30, 30</td>\n",
        "  </tr>\n",
        "</tbody>\n",
        "</table>\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34CmyakHFWR2"
      },
      "source": [
        "**Sample code for performance comparison between *k*-NN, RFR and AdaBoost algorithms**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XcKv4OkoE1-E"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "import sklearn.neighbors as skl_nb\n",
        "import sklearn.model_selection as skl_ms\n",
        "from sklearn.ensemble import AdaBoostRegressor"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFpvyhH0GCPr"
      },
      "source": [
        "df = pd.read_csv('./smallDSPWR.csv') ############### dataset file required\n",
        "\n",
        "halflife={\n",
        "          'Zr95':64.032,\n",
        "          'Nb95':34.991,\n",
        "          'Ru106':371.5,\n",
        "          'Cs134':2.064*365,\n",
        "          'Cs137':30.05*365,\n",
        "          'Eu154':8.601*365,\n",
        "          'Ce141':32.503,\n",
        "          'Ce144':284.89\n",
        "          }\n",
        "for iso in halflife:\n",
        "    df[iso+'A']=df[iso]*1e24*(np.log(2)/(halflife[iso]*86400))\n",
        "    \n",
        "### implement activity threshold\n",
        "for key in halflife:\n",
        "  df[key+'A']=df.mask(df[key+'A']<(0.001*(df['Cs137A'].min())), 0.0)[key+'A']\n",
        "\n",
        "df['TOT_A']=df.iloc[:, 19:27].sum(axis=1)\n",
        "############### feature selection\n",
        "df_f = df[(df['CT']/365<10.0)] #\n",
        "############### features\n",
        "features = ['Cs137A', 'Cs134A', 'Eu154A', 'Zr95A', 'Nb95A', 'Ru106A', 'Ce141A', 'Ce144A']\n",
        "# features = ['Cs137A', 'Cs134A', 'Eu154A']\n",
        "# features = ['Cs137A', 'Cs134A', 'Eu154A', 'tau', 'cherenkov']\n",
        "# features = ['Cs137A', 'Cs134A', 'Eu154A', 'tau', 'TOT_A']\n",
        "# features = ['Cs137A', 'Cs134A', 'Eu154A', 'tau', 'cherenkov', 'TOT_A']\n",
        "\n",
        "x = df_f[features] #prediction features\n",
        "y = df_f['BU'] #cooling time: output variable \n",
        "n_fold = 10\n",
        "out_feats = ['BU', 'CT', 'IE']\n",
        "\n",
        "models = []\n",
        "models.append(skl_nb.KNeighborsRegressor(n_neighbors=5, metric='canberra'))\n",
        "models.append(RandomForestRegressor(n_estimators=300, max_features=len(features)))\n",
        "models.append(AdaBoostRegressor(n_estimators=15, base_estimator=DecisionTreeRegressor(max_depth=15)))\n",
        "\n",
        "errors = np.zeros((n_fold, len(models)))\n",
        "cv = skl_ms.KFold (n_splits=n_fold, random_state=123, shuffle=True)\n",
        "\n",
        "\n",
        "for i, (train_index, val_index) in enumerate(cv.split(x)):\n",
        "    x_tr, x_vl = x.iloc[train_index], x.iloc[val_index]\n",
        "    y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
        "    scaler = StandardScaler()\n",
        "    x_train = scaler.fit_transform(x_tr)\n",
        "    x_val = scaler.transform(x_vl)\n",
        "    for m in range(np.shape(models)[0]):\n",
        "        model = models[m]\n",
        "        model.fit(x_train, y_train)\n",
        "        pred = model.predict(x_val)\n",
        "        rmse = mean_squared_error(y_val, pred, squared=False) #calculate rmse\n",
        "        errors[i, m] += rmse"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAKbT5CsErVu"
      },
      "source": [
        "**Create error visualizations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nEPjCcfdEOdU"
      },
      "source": [
        "plt.boxplot(errors)\n",
        "plt.title('10 fold cross-validation error [BU prediction for CT<10 years]')\n",
        "plt.yscale('log')\n",
        "plt.xticks(np.arange(3)+1, ('k-NN Regressor', 'Random Forest Regressor', 'AdaBoost Regressor'), rotation=0, fontsize=8)\n",
        "plt.ylabel('validation error', fontsize=8)\n",
        "plt.savefig('val_error_bu_ct0to10.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "import matplotlib.ticker as mtick  \n",
        "fig, axes = plt.subplots(nrows=1, ncols=3)\n",
        "ax0, ax1, ax2 = axes.flatten()\n",
        "\n",
        "ax0.boxplot(errors[:,0])\n",
        "ax0.set_yscale('linear')\n",
        "ax0.locator_params(axis='y', nbins=4)\n",
        "ax0.yaxis.set_major_formatter(mtick.StrMethodFormatter('{x:.3f}'))\n",
        "ax0.set_xticklabels(['k-NN Regressor'])\n",
        "ax0.set_ylabel('validation error')\n",
        "\n",
        "ax1.boxplot(errors[:,1])\n",
        "ax1.set_yscale('linear')\n",
        "ax1.locator_params(axis='y', nbins=4)\n",
        "ax1.yaxis.set_major_formatter(mtick.StrMethodFormatter('{x:.4f}'))\n",
        "ax1.set_xticklabels(['Random Forest Regressor'])\n",
        "\n",
        "ax2.boxplot(errors[:,2])\n",
        "ax2.set_yscale('linear')\n",
        "ax2.locator_params(axis='y', nbins=4)\n",
        "ax2.yaxis.set_major_formatter(mtick.StrMethodFormatter('{x:.3f}'))\n",
        "ax2.set_xticklabels(['AdaBoost Regressor'])\n",
        "fig.tight_layout()\n",
        "fig.subplots_adjust(top=0.91)\n",
        "fig.suptitle('10 fold cross-validation error [BU prediction for CT<10 years]', x=0.55, y=0.98)\n",
        "plt.savefig('val_error_bu_ct0to10_sub.png', dpi=300,bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQG5aHPFGfS2"
      },
      "source": [
        "**Optimum hyperparameters for neural networks**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1CAJh0OzovG"
      },
      "source": [
        "<!DOCTYPE html>\n",
        "<html>\n",
        "<head></head>\n",
        "<body>\n",
        "<table style=\"text-align:center; font-family: sans-serif; border-collapse:collapse;\">\n",
        "<caption style=\"text-align:left; padding: 10px;\"><strong>Table 2: Optimum hyperparameters for predictions using neural networks</strong></caption>\n",
        "<tfoot><tr><td colspan=\"100%\" style=\"text-align:left;\">\n",
        "&diams; For neural networks, the layer structure gives the total number of hidden layers and the total neurons in all hidden layers. <br/>\n",
        "These exclude an input layer of 64 neurons and an output layer of 3 neurons which were common to all network architectures used in the analysis.<br/><br/>\n",
        "&dagger; The learning rate given here outlines the initial learning rate whereas an adaptive learning rate scheme has been implemented.</td></tr></tfoot>\n",
        "<thead style=\"border-top: 2px solid black; border-bottom: 2px solid black;\">\n",
        "  <tr>\n",
        "    <th rowspan=\"2\" style=\"padding: 10px;\">CT Regime</th>\n",
        "    <th rowspan=\"2\" style=\"padding: 10px;\">Output Variable</th>\n",
        "    <th rowspan=\"2\" style=\"padding: 10px;\">Input Features</th>\n",
        "    <th colspan=\"2\" style=\"padding: 10px; border-bottom: 2px solid black;\">Hyperparameter Description</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td style=\"padding: 10px;\"><strong>Layer<br/>Structure</strong> &diams;</td>\n",
        "    <td style=\"padding: 10px;\"><strong>Learning<br/>Rate</strong> &dagger;</td>\n",
        "  </tr>\n",
        "</thead>\n",
        "<tbody style=\"border-bottom: 2px solid black;\">\n",
        "  <tr style=\"border-bottom: 2px solid black;\">\n",
        "    <td style=\"padding: 10px;\">CT &lt; 10 years</td>\n",
        "    <td style=\"padding: 10px;\">BU, IE, CT</td>\n",
        "    <td style=\"padding: 10px;\"><sup>141</sup>Ce, <sup>95</sup>Nb, <sup>95</sup>Zr, <sup>144</sup>Ce,<br/>\n",
        "<sup>106</sup>Ru, <sup>134</sup>Cs, <sup>154</sup>Eu, <sup>137</sup>Cs\n",
        "    </td>\n",
        "    <td style=\"padding: 10px;\">4, 480 neurons</td>\n",
        "    <td style=\"padding: 10px;\">0.001</td>\n",
        "  </tr>\n",
        "  <tr style=\"border-bottom: 2px solid black\">\n",
        "    <td style=\"padding: 10px;\">CT &lt; 20 years</td>\n",
        "    <td style=\"padding: 10px;\">BU, IE, CT</td>\n",
        "    <td style=\"padding: 10px;\"><sup>134</sup>Cs, <sup>154</sup>Eu, <sup>137</sup>Cs</td>\n",
        "    <td style=\"padding: 10px;\">19, 656 neurons</td>\n",
        "    <td style=\"padding: 10px;\">0.001</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td rowspan=\"6\" style=\"padding: 10px;\">20 &le; CT &le; 70 years</td>\n",
        "    <td rowspan=\"2\" style=\"padding: 10px;\">BU</td>\n",
        "    <td style=\"padding-top: 10px;\"><sup>134</sup>Cs, <sup>154</sup>Eu, <sup>137</sup>Cs, Tot_A, tau</td>\n",
        "    <td style=\"padding-top: 10px;\">6, 624 neurons</td>\n",
        "    <td style=\"padding-top: 10px;\">0.0001</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td><sup>134</sup>Cs, <sup>154</sup>Eu, <sup>137</sup>Cs, Cherenkov, tau</td>\n",
        "    <td>7, 512 neurons</td>\n",
        "    <td>0.0001</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td rowspan=\"2\">IE</td>\n",
        "    <td><sup>134</sup>Cs, <sup>154</sup>Eu, <sup>137</sup>Cs, Tot_A, tau</td>\n",
        "    <td>6, 624 neurons</td>\n",
        "    <td>0.0001</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td><sup>134</sup>Cs, <sup>154</sup>Eu, <sup>137</sup>Cs, Cherenkov, tau</td>\n",
        "    <td>7, 512 neurons</td>\n",
        "    <td>0.0001</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td rowspan=\"2\" style=\"padding: 10px;\">CT</td>\n",
        "    <td><sup>134</sup>Cs, <sup>154</sup>Eu, <sup>137</sup>Cs, Tot_A, tau</td>\n",
        "    <td>6, 624 neurons</td>\n",
        "    <td>0.0001</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td style=\"padding-bottom: 10px;\"><sup>134</sup>Cs, <sup>154</sup>Eu, <sup>137</sup>Cs, Cherenkov, tau</td>\n",
        "    <td style=\"padding-bottom: 10px;\">7, 512 neurons</td>\n",
        "    <td style=\"padding-bottom: 10px;\">0.0001</td>\n",
        "  </tr>\n",
        "</tbody>\n",
        "</table>\n",
        "</body>\n",
        "</html>\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ3yw9W6Ez9r"
      },
      "source": [
        "import kerastuner as kt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from kerastuner.tuners import RandomSearch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-12_QjqXGmKJ"
      },
      "source": [
        "df = pd.read_csv('./smallDSPWR.csv')  ############### dataset file required\n",
        "\n",
        "halflife={\n",
        "          'Zr95':64.032,\n",
        "          'Nb95':34.991,\n",
        "          'Ru106':371.5,\n",
        "          'Cs134':2.064*365,\n",
        "          'Cs137':30.05*365,\n",
        "          'Eu154':8.601*365,\n",
        "          'Ce141':32.503,\n",
        "          'Ce144':284.89\n",
        "          }\n",
        "for iso in halflife:\n",
        "    df[iso+'A']=df[iso]*1e24*(np.log(2)/(halflife[iso]*86400))\n",
        "    \n",
        "### implement activity threshold\n",
        "for key in halflife:\n",
        "  df[key+'A']=df.mask(df[key+'A']<(0.001*(df['Cs137A'].min())), 0.0)[key+'A']\n",
        "\n",
        "df['TOT_A']=df.iloc[:, 19:27].sum(axis=1)\n",
        "############### feature selection\n",
        "df_f = df[(df['CT']/365<20.0)] #\n",
        "############### features\n",
        "# features = ['Cs137A', 'Cs134A', 'Eu154A', 'Zr95A', 'Nb95A', 'Ru106A', 'Ce141A', 'Ce144A']\n",
        "features = ['Cs137A', 'Cs134A', 'Eu154A']\n",
        "# features = ['Cs137A', 'Cs134A', 'Eu154A', 'tau', 'cherenkov']\n",
        "# features = ['Cs137A', 'Cs134A', 'Eu154A', 'tau', 'TOT_A']\n",
        "# features = ['Cs137A', 'Cs134A', 'Eu154A', 'tau', 'cherenkov', 'TOT_A']\n",
        "\n",
        "x = df_f[features] #prediction features\n",
        "out_feats = ['BU', 'CT', 'IE']\n",
        "y = df_f[out_feats] \n",
        "n_fold = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oVrxonFhJHkt"
      },
      "source": [
        "**Set-up ANN model to predict fuel parameters**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhL0Qu5fGmnV"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(16, input_dim=3, kernel_initializer='RandomNormal', activation='tanh')) #layer 0\n",
        "model.add(Dense(64, activation='tanh'))  #layer 1\n",
        "model.add(Dense(16, activation='tanh')) #layer 2\n",
        "model.add(Dense(16, activation='tanh')) #layer 3\n",
        "model.add(Dense(16, activation='tanh')) #layer 4\n",
        "model.add(Dense(16, activation='tanh')) #layer 5\n",
        "model.add(Dense(16, activation='tanh')) #layer 6\n",
        "model.add(Dense(16, activation='tanh')) #layer 7\n",
        "model.add(Dense(16, activation='tanh')) #layer 8\n",
        "model.add(Dense(16, activation='tanh')) #layer 9\n",
        "model.add(Dense(16, activation='tanh')) #layer 10\n",
        "model.add(Dense(16, activation='tanh'))  #layer 11\n",
        "model.add(Dense(112, activation='tanh')) #layer 12\n",
        "model.add(Dense(128, activation='tanh')) #layer 13\n",
        "model.add(Dense(112, activation='tanh')) #layer 14\n",
        "model.add(Dense(16, activation='tanh')) #layer 15\n",
        "model.add(Dense(16, activation='tanh')) #layer 16\n",
        "model.add(Dense(16, activation='tanh')) #layer 17\n",
        "model.add(Dense(16, activation='tanh')) #layer 18\n",
        "model.add(Dense(16, activation='tanh')) #layer 19\n",
        "# model.add(Dense(16, activation='tanh')) #layer 20\n",
        "model.add(Dense(3, activation='linear'))\n",
        "model.summary()\n",
        "\n",
        "def nn(x_tr, y_tr, x_vl, y_vl):\n",
        "  import _datetime\n",
        "  # Define the Keras TensorBoard callback.\n",
        "  logdir=\"logs/fit/\" + _datetime.date.today().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  opt = keras.optimizers.Adamax(learning_rate=0.001)\n",
        "  reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.75, patience=5, min_lr=0.00001, verbose=1)\n",
        "  checkpoint = ModelCheckpoint(\"best_model.hdf5\", monitor='val_root_mean_squared_error', verbose=1,save_best_only=True, mode='auto', period=1)\n",
        "  tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "  model.compile(loss='mean_squared_error', optimizer=opt, metrics=[tf.keras.metrics.RootMeanSquaredError()])\n",
        "  history = model.fit(x_tr, y_tr, epochs=200, batch_size=1000,  verbose=1, validation_data=(x_vl, y_vl), callbacks=[tensorboard_callback, checkpoint, reduce_lr])\n",
        "  model.load_weights('best_model.hdf5')\n",
        "  buerr = mean_squared_error(scaler_y.inverse_transform(y_vl)[:,0], scaler_y.inverse_transform(model.predict(x_vl))[:,0], squared=False)\n",
        "  cterr = mean_squared_error(scaler_y.inverse_transform(y_vl)[:,1], scaler_y.inverse_transform(model.predict(x_vl))[:,1], squared=False)\n",
        "  ieerr = mean_squared_error(scaler_y.inverse_transform(y_vl)[:,2], scaler_y.inverse_transform(model.predict(x_vl))[:,2], squared=False)\n",
        "  return buerr, cterr, ieerr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGR2wghzJCVE"
      },
      "source": [
        "**Run training loop**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmW_uIIwGmZk"
      },
      "source": [
        "errors = np.zeros((n_fold, len(out_feats)))\n",
        "cv = skl_ms.KFold (n_splits=n_fold, random_state=123, shuffle=True)\n",
        "\n",
        "for i, (train_index, val_index) in enumerate(cv.split(x)):\n",
        "    x_tr, x_vl = x.iloc[train_index], x.iloc[val_index]\n",
        "    y_tr, y_vl = y.iloc[train_index], y.iloc[val_index]\n",
        "    scaler = StandardScaler()\n",
        "    x_train = scaler.fit_transform(x_tr)\n",
        "    x_val = scaler.transform(x_vl)\n",
        "    scaler_y = StandardScaler()\n",
        "    y_train = scaler_y.fit_transform(y_tr)\n",
        "    y_val = scaler_y.transform(y_vl)\n",
        "    burmse, ctrmse, iermse = nn(x_train, y_train, x_val, y_val)\n",
        "    errors[i] = burmse, ctrmse, iermse\n",
        "    print(f'loop {i} complete...')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cUbOX0WOI6Zd"
      },
      "source": [
        "**Create error visualizations**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ivVL-A-I0wi"
      },
      "source": [
        "import matplotlib.ticker as mtick  \n",
        "fig, axes = plt.subplots(nrows=1, ncols=3)\n",
        "ax0, ax1, ax2 = axes.flatten()\n",
        "\n",
        "ax0.boxplot(errors[:,0])\n",
        "ax0.set_yscale('linear')\n",
        "ax0.locator_params(axis='y', nbins=8)\n",
        "ax0.yaxis.set_major_formatter(mtick.StrMethodFormatter('{x:.2f}'))\n",
        "ax0.set_xticklabels([r'BU Error [$MWd/kgU]$'])\n",
        "ax0.set_ylabel('validation error')\n",
        "\n",
        "ax1.boxplot(errors[:,1])\n",
        "ax1.set_yscale('linear')\n",
        "ax1.locator_params(axis='y', nbins=10)\n",
        "ax1.yaxis.set_major_formatter(mtick.StrMethodFormatter('{x:.1f}'))\n",
        "ax1.set_xticklabels([r'CT Error [$days]$'])\n",
        "\n",
        "ax2.boxplot(errors[:,2])\n",
        "ax2.set_yscale('linear')\n",
        "ax2.locator_params(axis='y', nbins=10)\n",
        "ax2.yaxis.set_major_formatter(mtick.StrMethodFormatter('{x:.2f}'))\n",
        "ax2.set_xticklabels([r'IE Error [$wt.\\%$ U-235]'])\n",
        "fig.tight_layout()\n",
        "fig.subplots_adjust(top=0.91)\n",
        "fig.suptitle('10 fold cross-validation error w/ neural network [CT<20 years]', x=0.55, y=0.98)\n",
        "plt.savefig('val_error_NN_ct0to20n.png', dpi=300,bbox_inches='tight')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}